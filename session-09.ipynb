{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 9: From Single Models to Systems\n",
    "## Chaining Models Together\n",
    "\n",
    "**Session Length:** 2 hours\n",
    "\n",
    "**Today's Mission:** Move beyond single models to build multi-model systems. Learn how to chain the output of one model into the input of another, understand error cascades, and start thinking like a system designer.\n",
    "\n",
    "### Session Outline\n",
    "| Time | Activity |\n",
    "|------|----------|\n",
    "| 0:00-0:05 | Review: What bias patterns did you find? |\n",
    "| 0:05-0:30 | Part 1: What Is a Pipeline? |\n",
    "| 0:30-1:00 | Part 2: Building a Multi-Model Pipeline |\n",
    "| 1:00-1:40 | Part 3: Design Your Own Pipeline |\n",
    "| 1:40-2:00 | On Your Own: Build or modify a pipeline |\n",
    "\n",
    "### Key Vocabulary\n",
    "| Term | Definition |\n",
    "|------|-----------|\n",
    "| Pipeline | Chaining multiple models where output of one feeds into the next |\n",
    "| Error Cascade | When one model's mistake makes every downstream model worse |\n",
    "| System Design | Planning how multiple components work together |\n",
    "| Multi-Model System | A tool that uses more than one AI model |\n",
    "| Dependencies | When one part depends on another part working correctly |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: What Bias Patterns Did You Find? (0:00-0:05)\n",
    "\n",
    "Last session we investigated bias in AI models -- how training data creates blind spots, how paired-sentence tests reveal unequal treatment, and why this matters for real people. We also explored uncertainty and the difference between confidence and correctness.\n",
    "\n",
    "Today we shift gears. So far you have used **single models**: one input, one model, one output. Real AI systems do not work like that. Real systems chain multiple models together -- the output of one becomes the input of the next. This is powerful, but it introduces a critical new problem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell to install the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.47.1 pillow requests gradio -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: Restart Your Runtime\n",
    "\n",
    "After installing packages, you need to restart the runtime so Python can find them.\n",
    "\n",
    "**Go to: Runtime > Restart runtime**\n",
    "\n",
    "After restarting, come back here and continue running the cells below. You do NOT need to re-run the install cell -- the packages are already installed. Just start from the next code cell.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: What Is a Pipeline? (0:05-0:30)\n",
    "\n",
    "So far you have used single models: one input goes in, one output comes out.\n",
    "\n",
    "```\n",
    "Text --> [Sentiment Model] --> \"POSITIVE (92%)\"\n",
    "```\n",
    "\n",
    "Real AI systems chain multiple models together. The output of one becomes the input of the next:\n",
    "\n",
    "```\n",
    "Text --> [Emotion Model] --> emotions\n",
    "     --> [Topic Classifier] --> topic\n",
    "     --> [NER Model] --> key people and places\n",
    "     --> [Summarizer] --> summary\n",
    "```\n",
    "\n",
    "Five models, one function. Each answers a different question about the same text. This is a **multi-model system** -- and it is how most real AI applications work.\n",
    "\n",
    "### Building a Text Analysis Pipeline\n",
    "\n",
    "Let's build a comprehensive text analysis function that uses five different models on the same input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the models we need\n",
    "print(\"Loading models (this may take a minute)...\")\n",
    "\n",
    "emotions = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None\n",
    ")\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "sentiment = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "print(\"All 5 models loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_text_analysis(text):\n",
    "    \"\"\"\n",
    "    Perform multiple analyses on a piece of text using 5 models.\n",
    "    \"\"\"\n",
    "    print(\"COMPREHENSIVE TEXT ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Analyzing text ({len(text)} characters)...\\n\")\n",
    "\n",
    "    # 1. Emotional Tone\n",
    "    print(\"1. EMOTIONAL TONE\")\n",
    "    emotion_result = emotions(text[:500])[0]\n",
    "    top_emotions = sorted(emotion_result, key=lambda x: x['score'], reverse=True)[:3]\n",
    "    for e in top_emotions:\n",
    "        bar = \"*\" * int(e['score'] * 20)\n",
    "        print(f\"   {e['label']:10} {bar} {e['score']:.1%}\")\n",
    "\n",
    "    # 2. Topic Classification\n",
    "    print(\"\\n2. LIKELY TOPIC\")\n",
    "    topics = [\"technology\", \"politics\", \"sports\", \"entertainment\", \"science\", \"business\", \"personal\"]\n",
    "    topic_result = classifier(text[:500], topics)\n",
    "    print(f\"   Primary topic: {topic_result['labels'][0]} ({topic_result['scores'][0]:.1%})\")\n",
    "\n",
    "    # 3. Key Entities\n",
    "    print(\"\\n3. KEY ENTITIES\")\n",
    "    entity_result = ner(text)\n",
    "    if entity_result:\n",
    "        for e in entity_result[:5]:\n",
    "            print(f\"   {e['word']}: {e['entity_group']}\")\n",
    "    else:\n",
    "        print(\"   No named entities found\")\n",
    "\n",
    "    # 4. Summary\n",
    "    print(\"\\n4. SUMMARY\")\n",
    "    if len(text.split()) > 30:\n",
    "        summary = summarizer(text, max_length=60, min_length=20)[0]['summary_text']\n",
    "        print(f\"   {summary}\")\n",
    "    else:\n",
    "        print(f\"   (Text too short to summarize)\")\n",
    "\n",
    "    # 5. Overall Sentiment\n",
    "    print(\"\\n5. OVERALL SENTIMENT\")\n",
    "    sent_result = sentiment(text[:500])[0]\n",
    "    print(f\"   {sent_result['label']} ({sent_result['score']:.1%})\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Five models, one function. Each answered a different question.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Before running the next cell, explain: \"This function runs 5 different AI models on the same text. Watch how each model extracts different information from the same input.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"\"\"\n",
    "The breakthrough discovery in quantum computing announced yesterday by researchers\n",
    "at MIT has sent shockwaves through the tech industry. Dr. Sarah Chen and her team\n",
    "demonstrated a new method for maintaining quantum coherence at room temperature,\n",
    "potentially solving one of the biggest obstacles to practical quantum computers.\n",
    "Google and IBM stocks rose sharply on the news, while investors scrambled to\n",
    "understand the implications. Critics caution that scaling the technology remains\n",
    "a challenge, but optimists believe commercial quantum computers could arrive\n",
    "within five years.\n",
    "\"\"\"\n",
    "\n",
    "comprehensive_text_analysis(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how each model contributes something different:\n",
    "- The **emotion model** detects the emotional tone\n",
    "- The **topic classifier** identifies what the text is about\n",
    "- The **NER model** finds specific people, organizations, and places\n",
    "- The **summarizer** compresses the key information\n",
    "- The **sentiment model** gives an overall positive/negative reading\n",
    "\n",
    "No single model could do all of this. The power comes from **combining** them.\n",
    "\n",
    "### Student Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Ask students for a text to analyze -- a news paragraph, a social media post, or something from a class they are taking. Type it in and run the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_text = \"REPLACE WITH STUDENT SUGGESTION\"\n",
    "\n",
    "comprehensive_text_analysis(student_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building a Multi-Model Pipeline (0:30-1:00)\n",
    "\n",
    "The text analysis above runs five models **independently** on the same text. That is useful but it is not a true pipeline. In a true pipeline, the **output of one model becomes the input of the next**.\n",
    "\n",
    "Let's build one: Image --> Caption --> Mood --> Story.\n",
    "\n",
    "### The Image-to-Story Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart Your Runtime First\n",
    "\n",
    "Before loading image models, restart to free memory from the text models.\n",
    "\n",
    "**Go to: Runtime > Restart runtime**\n",
    "\n",
    "Then re-run the setup cell (imports and `load_image` helper) and continue here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "# Load image + text models for the pipeline\n",
    "print(\"Loading pipeline models...\")\n",
    "captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
    "image_classifier = pipeline(\"zero-shot-image-classification\", model=\"openai/clip-vit-base-patch32\")\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "print(\"Pipeline models loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_story(image_url, genre='fantasy'):\n",
    "    \"\"\"\n",
    "    A true pipeline: Image --> Caption --> Mood --> Story.\n",
    "    Each model's output feeds into the next model.\n",
    "    \"\"\"\n",
    "    print(\"IMAGE-TO-STORY PIPELINE\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    # Step 1: Load and show the image\n",
    "    print(\"\\nStep 1: Loading image...\")\n",
    "    image = load_image(image_url)\n",
    "    display(image.resize((300, 300)))\n",
    "\n",
    "    # Step 2: CAPTIONER generates a text description\n",
    "    print(\"\\nStep 2: Captioning image...\")\n",
    "    caption = captioner(image)[0]['generated_text']\n",
    "    print(f\"   Caption: {caption}\")\n",
    "\n",
    "    # Step 3: IMAGE CLASSIFIER detects the mood (uses the image)\n",
    "    print(\"\\nStep 3: Detecting mood...\")\n",
    "    moods = ['mysterious', 'cheerful', 'dramatic', 'peaceful', 'adventurous']\n",
    "    mood_result = image_classifier(image, candidate_labels=moods)\n",
    "    image_mood = mood_result[0]['label']\n",
    "    print(f\"   Mood: {image_mood}\")\n",
    "\n",
    "    # Step 4: GENERATOR creates a story from caption + mood + genre\n",
    "    print(\"\\nStep 4: Generating story...\")\n",
    "    story_prompts = {\n",
    "        'fantasy': f\"In a magical world, there was {caption}. The mood was {image_mood}. One day,\",\n",
    "        'mystery': f\"The detective studied the scene: {caption}. Something {image_mood} hung in the air. Then,\",\n",
    "        'scifi': f\"In the year 2150, {caption}. The atmosphere was {image_mood}. The AI calculated that\",\n",
    "    }\n",
    "    prompt = story_prompts.get(genre, story_prompts['fantasy'])\n",
    "\n",
    "    result = generator(prompt, max_length=120, do_sample=True, temperature=0.9)\n",
    "    story = result[0]['generated_text']\n",
    "\n",
    "    print(f\"\\n--- {genre.upper()} STORY ---\")\n",
    "    print(story)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 55)\n",
    "    print(\"Pipeline: Image --> Caption --> Mood --> Story\")\n",
    "    print(\"Each step depended on the step before it.\")\n",
    "\n",
    "    return caption, image_mood, story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Ask students for an image URL (or use the ones below). Run the pipeline. Then ask: \"What would happen if the captioner got the image wrong?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the pipeline with a sample image\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "\n",
    "caption, mood, story = image_to_story(image_url, genre='mystery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLIP Label-Set Comparison (Book Enhancement)\n",
    "\n",
    "Zero-shot image classification is powerful because **you define the labels**.\n",
    "\n",
    "The same image can produce different outputs depending on the categories you provide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the same image with two different label sets\n",
    "comparison_image = load_image(image_url)\n",
    "\n",
    "label_sets = {\n",
    "    \"Set A (object types)\": [\"cat\", \"dog\", \"bird\", \"rabbit\"],\n",
    "    \"Set B (scene mood)\": [\"peaceful\", \"chaotic\", \"playful\", \"mysterious\"],\n",
    "}\n",
    "\n",
    "print(\"CLIP LABEL-SET COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "for name, labels in label_sets.items():\n",
    "    predictions = image_classifier(comparison_image, candidate_labels=labels)\n",
    "    print(f\"\n",
    "{name}: {labels}\")\n",
    "    for pred in predictions[:3]:\n",
    "        print(f\"  - {pred['label']}: {pred['score']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Ask students for two custom label sets for the same image, then compare how the model behavior changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student-defined CLIP label sets\n",
    "student_labels_a = [\"REPLACE\", \"WITH\", \"LABELS\"]\n",
    "student_labels_b = [\"REPLACE\", \"WITH\", \"LABELS\"]\n",
    "\n",
    "if \"REPLACE\" not in student_labels_a and \"REPLACE\" not in student_labels_b:\n",
    "    print(\"Set A results:\")\n",
    "    for pred in image_classifier(comparison_image, candidate_labels=student_labels_a)[:3]:\n",
    "        print(f\"  - {pred['label']}: {pred['score']:.1%}\")\n",
    "\n",
    "    print(\"\n",
    "Set B results:\")\n",
    "    for pred in image_classifier(comparison_image, candidate_labels=student_labels_b)[:3]:\n",
    "        print(f\"  - {pred['label']}: {pred['score']:.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Cascades: When One Mistake Ruins Everything\n",
    "\n",
    "In the pipeline above, the caption feeds into the story. What happens if the caption is wrong? Let's find out by deliberately overriding the caption with a wrong description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_story_with_override(image_url, fake_caption, genre='fantasy'):\n",
    "    \"\"\"\n",
    "    Same pipeline, but we override the caption to simulate an error.\n",
    "    This shows how one mistake cascades through the system.\n",
    "    \"\"\"\n",
    "    print(\"ERROR CASCADE DEMO\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    # Step 1: Load image\n",
    "    image = load_image(image_url)\n",
    "    display(image.resize((300, 300)))\n",
    "\n",
    "    # Step 2: Use the WRONG caption (simulating a captioner error)\n",
    "    print(f\"\\nReal image: (see above)\")\n",
    "    print(f\"WRONG caption: {fake_caption}\")\n",
    "\n",
    "    # Step 3: Mood still comes from the image (correct)\n",
    "    moods = ['mysterious', 'cheerful', 'dramatic', 'peaceful', 'adventurous']\n",
    "    mood_result = image_classifier(image, candidate_labels=moods)\n",
    "    image_mood = mood_result[0]['label']\n",
    "    print(f\"Mood: {image_mood}\")\n",
    "\n",
    "    # Step 4: Story is built from the WRONG caption\n",
    "    prompt = f\"In a magical world, there was {fake_caption}. The mood was {image_mood}. One day,\"\n",
    "    result = generator(prompt, max_length=120, do_sample=True, temperature=0.9)\n",
    "    story = result[0]['generated_text']\n",
    "\n",
    "    print(f\"\\n--- STORY (built from wrong caption) ---\")\n",
    "    print(story)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 55)\n",
    "    print(\"The story is about something completely different from the image!\")\n",
    "    print(\"This is an ERROR CASCADE -- one mistake affected everything downstream.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image is a cat, but we tell the pipeline it's something else\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "\n",
    "image_to_story_with_override(\n",
    "    image_url,\n",
    "    fake_caption=\"a rocket launching into space from a desert launchpad\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image shows a cat, but because we fed a wrong caption (\"a rocket launching into space\"), the entire story is about rockets and space -- nothing to do with the actual image.\n",
    "\n",
    "**In a real system** -- say, an accessibility tool that describes images for blind users -- a wrong caption means a wrong description. One mistake affects everything downstream. This is why **system design** matters, not just individual model accuracy.\n",
    "\n",
    "### Student Pipeline Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Have students suggest an image URL and a genre. Run the pipeline. Then ask them to suggest a deliberately wrong caption and see how the story changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_image_url = \"REPLACE WITH IMAGE URL\"\n",
    "student_genre = \"fantasy\"  # Try: fantasy, mystery, or scifi\n",
    "\n",
    "if \"REPLACE\" not in student_image_url:\n",
    "    caption, mood, story = image_to_story(student_image_url, genre=student_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ASK AI ABOUT THIS**\n",
    ">\n",
    "> Copy the `image_to_story` function into Claude or ChatGPT and ask:\n",
    ">\n",
    "> *\"If the captioner said 'a dog playing fetch' but the image actually showed a cat sleeping, how would that affect each step of this pipeline? Walk me through the error cascade.\"*\n",
    ">\n",
    "> This is how real programmers learn -- by asking questions about code they encounter.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Design Your Own Pipeline (1:00-1:25)\n",
    "\n",
    "Now that you understand how pipelines work -- and how they can fail -- let's think about designing new ones.\n",
    "\n",
    "### Pipeline Design Exercise\n",
    "\n",
    "For each scenario below, think about:\n",
    "1. What models would you need?\n",
    "2. What order would they run in?\n",
    "3. Where could errors cascade?\n",
    "\n",
    "### Scenario A: News Digest Tool\n",
    "**Goal:** Take a news article, find the key people, analyze sentiment about each person, and summarize.\n",
    "\n",
    "```\n",
    "Article --> [NER] --> people mentioned\n",
    "        --> [Sentiment] --> sentiment per sentence\n",
    "        --> [Summarizer] --> summary\n",
    "Combine: Who was mentioned and how the article feels about them\n",
    "```\n",
    "\n",
    "### Scenario B: Social Media Post Generator\n",
    "**Goal:** Take an image, caption it, detect the mood, and generate a social media post.\n",
    "\n",
    "```\n",
    "Image --> [Captioner] --> description\n",
    "      --> [Mood Detector] --> mood\n",
    "      --> [Generator] --> social media post matching the mood\n",
    "```\n",
    "\n",
    "### Scenario C: Study Assistant\n",
    "**Goal:** Take student homework, classify the subject, estimate difficulty, and suggest study approach.\n",
    "\n",
    "```\n",
    "Homework text --> [Topic Classifier] --> subject\n",
    "              --> [Difficulty Classifier] --> easy/medium/hard\n",
    "              --> [Summarizer] --> key concepts\n",
    "Combine: \"This is a [difficulty] [subject] assignment about [concepts]\"\n",
    "```\n",
    "\n",
    "### Your Pipeline Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Have each student (or the group together) pick one scenario and describe the pipeline verbally. Diagram it on screen. They do NOT need to code it -- the goal is system design thinking. Ask: \"Where could an error in step 1 ruin step 3?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If students want to try building Scenario A, here's a starter:\n",
    "# (This is optional -- the main goal is the design exercise above)\n",
    "\n",
    "# Uncomment and modify to try:\n",
    "# from transformers import pipeline\n",
    "#\n",
    "# ner = pipeline(\"ner\", grouped_entities=True)\n",
    "# sentiment = pipeline(\"sentiment-analysis\")\n",
    "# summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "#\n",
    "# def news_digest(article):\n",
    "#     print(\"NEWS DIGEST PIPELINE\")\n",
    "#     print(\"=\" * 50)\n",
    "#\n",
    "#     # Step 1: Find key entities\n",
    "#     entities = ner(article)\n",
    "#     people = [e['word'] for e in entities if e['entity_group'] == 'PER']\n",
    "#     print(f\"People mentioned: {people}\")\n",
    "#\n",
    "#     # Step 2: Overall sentiment\n",
    "#     sent = sentiment(article[:500])[0]\n",
    "#     print(f\"Overall tone: {sent['label']} ({sent['score']:.1%})\")\n",
    "#\n",
    "#     # Step 3: Summary\n",
    "#     if len(article.split()) > 30:\n",
    "#         summary = summarizer(article, max_length=60, min_length=20)[0]['summary_text']\n",
    "#         print(f\"Summary: {summary}\")\n",
    "#\n",
    "# # Test it:\n",
    "# news_digest(\"Your article text here...\")\n",
    "\n",
    "print(\"(Uncomment the code above to try the news digest pipeline)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ASK AI ABOUT THIS**\n",
    ">\n",
    "> Describe one of the pipeline scenarios to Claude or ChatGPT and ask:\n",
    ">\n",
    "> *\"I want to build an AI pipeline that [describe your scenario]. What models would I need, what order should they run in, and where could errors cascade?\"*\n",
    ">\n",
    "> This is how real programmers learn -- by asking questions about code they encounter.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Your Own (1:40-2:00)\n",
    "\n",
    "### Experiment 1: Modify the Image-to-Story Pipeline\n",
    "\n",
    "Add a step to the pipeline. Ideas:\n",
    "- Add sentiment analysis of the generated story\n",
    "- Add a \"title generator\" step\n",
    "- Try different genres and compare the stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your modified pipeline\n",
    "# Start from the image_to_story function and add your own steps\n",
    "\n",
    "# Example: Run the pipeline on a new image with all three genres\n",
    "test_url = \"REPLACE WITH AN IMAGE URL\"\n",
    "\n",
    "if \"REPLACE\" not in test_url:\n",
    "    for genre in ['fantasy', 'mystery', 'scifi']:\n",
    "        print(\"\\n\" + \"#\" * 60 + \"\\n\")\n",
    "        image_to_story(test_url, genre=genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Design a Pipeline on Paper\n",
    "\n",
    "Sketch a pipeline for something YOU care about. Write it out:\n",
    "\n",
    "**My Pipeline Idea:**\n",
    "\n",
    "**Step 1:** Input is ___________\n",
    "\n",
    "**Step 2:** Model _________ produces _________\n",
    "\n",
    "**Step 3:** Model _________ takes that and produces _________\n",
    "\n",
    "**Step 4:** Model _________ takes that and produces _________\n",
    "\n",
    "**Final Output:** _________\n",
    "\n",
    "**Where could errors cascade?** _________\n",
    "\n",
    "### Experiment 3: Error Cascade Exploration\n",
    "\n",
    "Try the error cascade demo with different wrong captions. How wrong does the caption need to be before the story becomes completely unrelated to the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different wrong captions\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/1200px-Cat_November_2010-1a.jpg\"\n",
    "\n",
    "wrong_captions = [\n",
    "    \"a small dog sleeping on a couch\",      # Close but wrong animal\n",
    "    \"a person reading a book in a library\",  # Completely different scene\n",
    "    \"an explosion in a factory\",             # Wildly different\n",
    "]\n",
    "\n",
    "for caption in wrong_captions:\n",
    "    print(\"\\n\" + \"#\" * 60)\n",
    "    image_to_story_with_override(image_url, caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Pipeline App\n",
    "\n",
    "In Session 3 you wrapped one model in Gradio. In Session 6 you compared three models side by side. Now let's wrap an entire **multi-model pipeline** into an app.\n",
    "\n",
    "Upload any image, pick a genre, and the pipeline runs all three steps (caption, mood, story) behind the scenes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def gradio_image_to_story(image, genre):\n",
    "    if image is None:\n",
    "        return \"Upload an image to get started.\"\n",
    "\n",
    "    # Step 1: Caption\n",
    "    caption = captioner(image)[0]['generated_text']\n",
    "\n",
    "    # Step 2: Mood\n",
    "    moods = ['mysterious', 'cheerful', 'dramatic', 'peaceful', 'adventurous']\n",
    "    mood_result = image_classifier(image, candidate_labels=moods)\n",
    "    image_mood = mood_result[0]['label']\n",
    "\n",
    "    # Step 3: Story\n",
    "    story_prompts = {\n",
    "        'fantasy': f\"In a magical world, there was {caption}. The mood was {image_mood}. One day,\",\n",
    "        'mystery': f\"The detective studied the scene: {caption}. Something {image_mood} hung in the air. Then,\",\n",
    "        'scifi': f\"In the year 2150, {caption}. The atmosphere was {image_mood}. The AI calculated that\",\n",
    "    }\n",
    "    prompt = story_prompts.get(genre, story_prompts['fantasy'])\n",
    "    result = generator(prompt, max_length=120, do_sample=True, temperature=0.9)\n",
    "    story = result[0]['generated_text']\n",
    "\n",
    "    return f\"Caption: {caption}\\nMood: {image_mood}\\n\\n--- {genre.upper()} STORY ---\\n{story}\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=gradio_image_to_story,\n",
    "    inputs=[\n",
    "        gr.Image(label=\"Upload an image\", type=\"pil\"),\n",
    "        gr.Dropdown(choices=[\"fantasy\", \"mystery\", \"scifi\"], value=\"fantasy\", label=\"Genre\"),\n",
    "    ],\n",
    "    outputs=gr.Textbox(label=\"Generated Story\", lines=8),\n",
    "    title=\"Image-to-Story Generator\",\n",
    "    description=\"Upload any image. AI will caption it, detect the mood, and write a story.\",\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** This is the payoff for the Gradio progression: Session 3 (one model), Session 6 (three models side by side), now a full pipeline with image upload and a dropdown. Students can drag-and-drop photos from their phone. The shareable link previews what their Session 11-12 project could look like. Stop the demo by clicking the stop button or restarting the runtime when done.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Checklist: Before You Leave\n",
    "\n",
    "- [ ] Ran the comprehensive text analysis (5 models on one input)\n",
    "- [ ] Built and ran the image-to-story pipeline\n",
    "- [ ] Saw how a wrong caption cascades into a wrong story\n",
    "- [ ] Designed a pipeline on paper (identified models, order, and error points)\n",
    "- [ ] Discussed where errors cascade in multi-model systems\n",
    "- [ ] Saved your work (File > Save a copy in Drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Looking Ahead\n",
    "\n",
    "Next session, we bring everything together. You know what models can do (Sessions 2-3). You know their limits (Sessions 6-8). You know how to chain them (today). Next session: **prompt engineering** -- the art of controlling models through careful input design -- and **project planning**. By the end of Session 10, you will have a project idea and a plan to build it.\n",
    "\n",
    "See you next session.\n",
    "\n",
    "---\n",
    "\n",
    "*Youth Horizons AI Researcher Program - Level 2*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}