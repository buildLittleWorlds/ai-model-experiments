{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2: Data Collection and Representation\n",
    "## From Clicking Buttons to Writing Code\n",
    "\n",
    "**Session Length:** 2 hours\n",
    "\n",
    "**Today's Mission:** Run real AI models using code, understand how pipelines work, and discover why different models need different kinds of input.\n",
    "\n",
    "### Session Outline\n",
    "| Time | Activity |\n",
    "|------|----------|\n",
    "| 0:00-0:10 | Quick review of Session 1 discoveries |\n",
    "| 0:10-0:20 | Colab Basics (compressed) |\n",
    "| 0:20-0:45 | First Code, First Pipeline: Sentiment Analysis |\n",
    "| 0:45-1:15 | Representation Matters: Multiple Pipelines |\n",
    "| 1:15-1:45 | HF Browser: Model ecosystem + Model cards |\n",
    "| 1:45-2:00 | On Your Own: Full pipeline exploration |\n",
    "\n",
    "### Key Vocabulary\n",
    "| Term | Definition |\n",
    "|------|-----------|\n",
    "| Pipeline | A ready-to-use AI tool that handles input → model → output |\n",
    "| Sentiment Analysis | AI that determines if text is positive or negative |\n",
    "| Confidence Score | How sure the model is about its answer (0% to 100%) |\n",
    "| Google Colab | A free cloud computer for running Python code |\n",
    "| Representation | How data is formatted for a model to understand |\n",
    "| Model ID | The unique name for a model on Hugging Face (e.g. `distilbert-base-uncased-finetuned-sst-2-english`) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Quick Review (10 minutes)\n",
    "\n",
    "### What did you discover?\n",
    "\n",
    "From Session 1, we learned:\n",
    "- Every AI tool follows **INPUT → MODEL → OUTPUT**\n",
    "- **Rule-based** AI: the programmer writes the rules\n",
    "- **Model-based** AI: the computer learns patterns from data\n",
    "- The \"knowledge\" lives in the **training data**, not the code\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask each student to share one thing they explored between sessions. Keep this brief — 1-2 minutes per student.\n",
    "\n",
    "### Today's Big Idea\n",
    "\n",
    "Last session, we clicked buttons on websites to use AI tools. Today, we write code to run the **same kinds of models** ourselves.\n",
    "\n",
    "**Why bother with code?** Because code gives you power:\n",
    "- Process many inputs at once\n",
    "- Customize how the model works\n",
    "- Combine models in creative ways\n",
    "- Build your own tools others can use\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Colab Basics (10 minutes)\n",
    "\n",
    "### What is Google Colab?\n",
    "\n",
    "**Google Colab** is a free cloud computer that runs in your browser. You write code, and Google's computers run it for you.\n",
    "\n",
    "A notebook is made of **cells**:\n",
    "- **Markdown cells** (like this one) — for text and explanations\n",
    "- **Code cells** — for Python code that actually runs\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Demo running cells quickly — students watch, they'll practice on their own time. Run through each of the following cells in about 2 minutes total.\n",
    "\n",
    "### Run Your First Code Cell\n",
    "\n",
    "Click the cell below and press **Shift+Enter** (or click the Play button)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code cell!\n",
    "# Lines starting with # are comments - they don't run\n",
    "print(\"Hello! You just ran your first code cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables and Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables store information\n",
    "my_name = \"Your Name Here\"  # Change this!\n",
    "my_age = 14  # Change this!\n",
    "\n",
    "# Python can do math\n",
    "age_in_10_years = my_age + 10\n",
    "\n",
    "# f-strings let you mix variables into text\n",
    "print(f\"Hi, I'm {my_name}!\")\n",
    "print(f\"In 10 years, I'll be {age_in_10_years} years old.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "\n",
    "A **list** holds multiple items. We'll use lists to process multiple inputs through AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of things\n",
    "favorite_things = [\"pizza\", \"video games\", \"AI\", \"music\"]\n",
    "\n",
    "# Print each item\n",
    "for thing in favorite_things:\n",
    "    print(f\"I like {thing}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Colab Tips\n",
    "\n",
    "| Shortcut | What it does |\n",
    "|----------|-------------|\n",
    "| Shift+Enter | Run cell and move to next |\n",
    "| Ctrl+Enter | Run cell and stay |\n",
    "| Ctrl+M B | Add new cell below |\n",
    "| Ctrl+M D | Delete current cell |\n",
    "\n",
    "**Important:** Cells run in order. If you skip a cell, later cells might break.\n",
    "\n",
    "---\n",
    "\n",
    "### When Things Don't Work\n",
    "\n",
    "Code fails sometimes. Models don't load. Errors appear in red. This is completely normal — it happens to professional programmers every day.\n",
    "\n",
    "**When you see an error:**\n",
    "1. **Read the last line** of the error message — it usually tells you what's wrong\n",
    "2. **Check the obvious:** Did you run the cells in order? Spelling correct? Missing quote mark?\n",
    "3. **Ask for help:** Paste the error into ChatGPT/Claude — they're great at explaining errors\n",
    "4. **Restart:** Runtime → Restart Runtime (clears everything, lets you start fresh)\n",
    "\n",
    "Errors aren't failures — they're information.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: First Code, First Pipeline — Sentiment Analysis (25 minutes)\n",
    "\n",
    "Now let's run a real AI model!\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Run each cell live. Pause after the first result to make sure students see the output. This is the \"wow\" moment — code that does something intelligent.\n",
    "\n",
    "### Step 1: Install the Library\n",
    "\n",
    "First, we need to install **transformers** — Hugging Face's library for running AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Hugging Face transformers library\n",
    "# The ! means \"run this as a terminal command\"\n",
    "# The -q means \"quiet\" (less output)\n",
    "!pip install transformers==4.47.1 -q\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load a Sentiment Analysis Model\n",
    "\n",
    "**Sentiment analysis** = AI that determines if text is positive or negative.\n",
    "\n",
    "Run this cell to load the model (first time takes about 30 seconds to download):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pipeline function\n",
    "from transformers import pipeline\n",
    "\n",
    "# Create a sentiment analysis pipeline\n",
    "# This downloads a pre-trained model automatically\n",
    "sentiment = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "print(\"Model loaded and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Analyze Some Text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a simple sentence\n",
    "result = sentiment(\"I love learning about AI!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Output\n",
    "\n",
    "You should see something like:\n",
    "```python\n",
    "[{'label': 'POSITIVE', 'score': 0.9998}]\n",
    "```\n",
    "\n",
    "- **label**: POSITIVE or NEGATIVE\n",
    "- **score**: How confident the model is (0 to 1, where 1 = 100% confident)\n",
    "\n",
    "### Try a Student Suggestion\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask a student for a sentence. Type it into the cell below and run it live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE with a student's suggestion\n",
    "student_text = \"REPLACE WITH STUDENT SUGGESTION\"\n",
    "\n",
    "result = sentiment(student_text)\n",
    "\n",
    "# Print it nicely\n",
    "print(f\"Text: {student_text}\")\n",
    "print(f\"Sentiment: {result[0]['label']}\")\n",
    "print(f\"Confidence: {result[0]['score']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Analysis: Many Texts at Once\n",
    "\n",
    "One power of code — process many inputs at once!\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask students for 2-3 of these sentences. Mix in some tricky ones (sarcasm, mixed feelings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A batch of texts to analyze\n",
    "texts = [\n",
    "    \"I absolutely love this!\",\n",
    "    \"This is terrible and I hate it.\",\n",
    "    \"The weather is nice today.\",\n",
    "    \"Oh great, another Monday.\",\n",
    "    \"The food was good but the service was slow.\",\n",
    "    \"I'm not unhappy with the results.\",\n",
    "    \"REPLACE WITH STUDENT SUGGESTION\"\n",
    "]\n",
    "\n",
    "# Analyze all at once\n",
    "results = sentiment(texts)\n",
    "\n",
    "# Print each result\n",
    "print(\"SENTIMENT ANALYSIS RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "for text, result in zip(texts, results):\n",
    "    label = result['label']\n",
    "    score = result['score']\n",
    "    print(f\"\\n{text}\")\n",
    "    print(f\"  --> {label} ({score:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion Questions\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Pause here for 2-3 minutes of discussion. These questions connect back to Session 1's \"where does the knowledge live?\" theme.\n",
    "\n",
    "Look at the results above:\n",
    "\n",
    "1. **Did the model get the sarcasm right?** (\"Oh great, another Monday\")\n",
    "2. **How did it handle mixed feelings?** (The food/service one)\n",
    "3. **What about the double negative?** (\"I'm not unhappy\")\n",
    "4. **Where did this model learn what's positive and negative?** (Training data — thousands of labeled reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ASK AI ABOUT THIS**\n",
    ">\n",
    "> Copy this code into Claude or ChatGPT:\n",
    ">\n",
    "> ```python\n",
    "> from transformers import pipeline\n",
    "> sentiment = pipeline(\"sentiment-analysis\")\n",
    "> result = sentiment(\"I love learning about AI!\")\n",
    "> print(result)\n",
    "> ```\n",
    ">\n",
    "> Ask: *\"What is this code doing step by step? Explain it for someone who doesn't know Python.\"*\n",
    ">\n",
    "> This is how real programmers learn — by asking questions about code they encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **FIND A MODEL: Sentiment / Text Classification**\n",
    ">\n",
    "> The default sentiment model was trained on English movie reviews. But there are hundreds of text classification models on Hugging Face — trained on tweets, news, product reviews, and more.\n",
    ">\n",
    "> 1. Go to [huggingface.co/models?pipeline_tag=text-classification&sort=downloads](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads)\n",
    "> 2. Browse the top results. Click on one that looks interesting.\n",
    "> 3. **Read the model card:** What was it trained on? What language? Any known limitations?\n",
    "> 4. Copy the model ID (it looks like `author/model-name`) and try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap in your own text classification model!\n",
    "# Step 1: Go to huggingface.co/models?pipeline_tag=text-classification&sort=downloads\n",
    "# Step 2: Find a model, click it, read its card\n",
    "# Step 3: Copy the model ID and paste it below\n",
    "\n",
    "my_sentiment_model = \"PASTE YOUR MODEL ID HERE\"\n",
    "# Example: \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Uncomment these lines when you have a model ID:\n",
    "# custom_sentiment = pipeline(\"text-classification\", model=my_sentiment_model)\n",
    "# test_texts = [\"I love this!\", \"This is boring.\", \"I'm not sure how I feel.\"]\n",
    "# for text in test_texts:\n",
    "#     result = custom_sentiment(text)\n",
    "#     print(f\"{text}\")\n",
    "#     print(f\"  -> {result[0]['label']} ({result[0]['score']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Representation Matters — Multiple Pipelines (30 minutes)\n",
    "\n",
    "Here's something important: **each AI pipeline expects a different kind of input.**\n",
    "\n",
    "- Sentiment analysis wants **raw text**\n",
    "- Question answering wants **a question AND a context passage**\n",
    "- Zero-shot classification wants **text AND a list of categories**\n",
    "- Summarization wants **long text**\n",
    "\n",
    "The way you **represent** (format) your data determines what the model can do with it. This is what \"representation\" means in AI.\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Run each pipeline live. For zero-shot, ask students what categories to use. For QA, ask what questions to try. The key takeaway is that different models need different input formats.\n",
    "\n",
    "---\n",
    "\n",
    "### Pipeline 2: Zero-Shot Classification\n",
    "\n",
    "**What it does:** Classifies text into categories you define — even categories it wasn't specifically trained on!\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask students: \"What should we classify? What categories?\" Type their suggestions into the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Example: What category does this belong to?\n",
    "text = \"I need to submit my math homework by Friday\"\n",
    "categories = [\"school\", \"sports\", \"entertainment\", \"food\"]\n",
    "\n",
    "result = classifier(text, categories)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"\\nCategory scores:\")\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    print(f\"  {label}: {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Student Suggestions\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask students for text and categories. Type them in below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE with student suggestions\n",
    "student_text = \"REPLACE WITH STUDENT SUGGESTION\"\n",
    "student_categories = [\"REPLACE\", \"WITH\", \"STUDENT SUGGESTIONS\"]\n",
    "\n",
    "result = classifier(student_text, student_categories)\n",
    "\n",
    "print(f\"Text: {student_text}\")\n",
    "print(f\"\\nCategory scores:\")\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    print(f\"  {label}: {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pipeline 2.5: Language Detection (Book Enhancement)\n",
    "\n",
    "**What it does:** Detects the language of a sentence.\n",
    "\n",
    "This is useful when your AI tool might receive input from multilingual users.\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask students to suggest sentences in different languages. Also test mixed-language text and emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a language detection model\n",
    "language_classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"papluca/xlm-roberta-base-language-detection\"\n",
    ")\n",
    "\n",
    "language_examples = [\n",
    "    \"The science fair project was harder than I expected.\",\n",
    "    \"La biblioteca de mi escuela cierra a las cinco.\",\n",
    "    \"日本の桜は美しいです。\",\n",
    "    \"Je suis fatigue mais tres fier de mon projet.\",\n",
    "    \"This class es muy interesante y divertida!\"\n",
    "]\n",
    "\n",
    "print(\"LANGUAGE DETECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "for text in language_examples:\n",
    "    result = language_classifier(text)[0]\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted language code: {result['label']} ({result['score']:.1%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student language test\n",
    "student_language_text = \"REPLACE WITH STUDENT SUGGESTION\"\n",
    "\n",
    "if \"REPLACE\" not in student_language_text:\n",
    "    result = language_classifier(student_language_text)[0]\n",
    "    print(f\"Text: {student_language_text}\")\n",
    "    print(f\"Predicted language code: {result['label']} ({result['score']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **FIND A MODEL: Zero-Shot Classification**\n",
    ">\n",
    "> Zero-shot classification models come in different sizes and languages. Some are better at specific domains.\n",
    ">\n",
    "> 1. Go to [huggingface.co/models?pipeline_tag=zero-shot-classification&sort=downloads](https://huggingface.co/models?pipeline_tag=zero-shot-classification&sort=downloads)\n",
    "> 2. Browse the top models — notice the sizes (some tiny, some very large)\n",
    "> 3. Click one and **read its model card**: Is it multilingual? What was it trained on?\n",
    "> 4. Copy the model ID and swap it in below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap in your own zero-shot classification model!\n",
    "# Step 1: Go to huggingface.co/models?pipeline_tag=zero-shot-classification&sort=downloads\n",
    "# Step 2: Find a model, click it, read its card\n",
    "# Step 3: Copy the model ID and paste it below\n",
    "\n",
    "my_zero_shot_model = \"PASTE YOUR MODEL ID HERE\"\n",
    "# Example: \"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\"\n",
    "\n",
    "# Uncomment these lines when you have a model ID:\n",
    "# custom_classifier = pipeline(\"zero-shot-classification\", model=my_zero_shot_model)\n",
    "# result = custom_classifier(\n",
    "#     \"I need to finish my science project this weekend\",\n",
    "#     candidate_labels=[\"school\", \"hobbies\", \"family\", \"sports\"]\n",
    "# )\n",
    "# for label, score in zip(result['labels'], result['scores']):\n",
    "#     print(f\"  {label}: {score:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pipeline 3: Question Answering\n",
    "\n",
    "**What it does:** Answers questions based on a given context (passage of text).\n",
    "\n",
    "Notice: this pipeline needs **two inputs** — a question AND a context. The model can only answer from what's in the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the question-answering pipeline\n",
    "qa = pipeline(\"question-answering\")\n",
    "\n",
    "# The context is the text the AI will search for answers\n",
    "context = \"\"\"\n",
    "The Python programming language was created by Guido van Rossum and was first\n",
    "released in 1991. Python is known for its simple and readable syntax, making\n",
    "it popular for beginners. It is widely used in artificial intelligence,\n",
    "web development, and scientific computing. Major companies like Google,\n",
    "Netflix, and Instagram use Python in their technology stacks.\n",
    "\"\"\"\n",
    "\n",
    "# Ask a question\n",
    "question = \"Who created Python?\"\n",
    "\n",
    "result = qa(question=question, context=context)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Confidence: {result['score']:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try multiple questions about the same context\n",
    "questions = [\n",
    "    \"When was Python released?\",\n",
    "    \"What is Python used for?\",\n",
    "    \"Which companies use Python?\",\n",
    "    \"Why is Python popular with beginners?\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    result = qa(question=q, context=context)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {result['answer']} ({result['score']:.1%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **FIND A MODEL: Question Answering**\n",
    ">\n",
    "> The default QA model was trained on English Wikipedia. Some QA models specialize in medical text, legal documents, scientific papers, or other languages.\n",
    ">\n",
    "> 1. Go to [huggingface.co/models?pipeline_tag=question-answering&sort=downloads](https://huggingface.co/models?pipeline_tag=question-answering&sort=downloads)\n",
    "> 2. Try filtering by language or search for \"biomedical\", \"legal\", or \"multilingual\"\n",
    "> 3. **Read the model card**: What domain or language is it designed for? What dataset was it trained on?\n",
    "> 4. Swap it in below and test it with a relevant context passage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap in your own question-answering model!\n",
    "# Step 1: Go to huggingface.co/models?pipeline_tag=question-answering&sort=downloads\n",
    "# Step 2: Find a model, click it, read its card\n",
    "# Step 3: Copy the model ID and paste it below\n",
    "\n",
    "my_qa_model = \"PASTE YOUR MODEL ID HERE\"\n",
    "# Example: \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# Uncomment these lines when you have a model ID:\n",
    "# custom_qa = pipeline(\"question-answering\", model=my_qa_model)\n",
    "#\n",
    "# # Write a context passage relevant to your model's specialty\n",
    "# my_context = \"PASTE A RELEVANT TEXT PASSAGE HERE\"\n",
    "# my_question = \"WHAT DO YOU WANT TO KNOW?\"\n",
    "#\n",
    "# result = custom_qa(question=my_question, context=my_context)\n",
    "# print(f\"Q: {my_question}\")\n",
    "# print(f\"A: {result['answer']} ({result['score']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pipeline 4: Summarization\n",
    "\n",
    "**What it does:** Takes long text and creates a shorter summary.\n",
    "\n",
    "Notice: this pipeline needs **long text** — short text doesn't give it enough to summarize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "# A long piece of text to summarize\n",
    "long_text = \"\"\"\n",
    "Artificial intelligence has made remarkable progress in recent years,\n",
    "transforming many aspects of our daily lives. From virtual assistants\n",
    "like Siri and Alexa to recommendation systems on Netflix and Spotify,\n",
    "AI is now deeply embedded in the technology we use every day.\n",
    "\n",
    "Machine learning, a subset of AI, allows computers to learn from data\n",
    "without being explicitly programmed. This has led to breakthroughs in\n",
    "image recognition, natural language processing, and even game playing.\n",
    "In 2016, Google's AlphaGo defeated the world champion in the ancient\n",
    "game of Go, a feat that many thought was decades away.\n",
    "\n",
    "However, AI also raises important ethical questions about privacy,\n",
    "bias, and the future of work. As AI systems become more capable,\n",
    "society must grapple with how to ensure they are developed and\n",
    "deployed responsibly.\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary\n",
    "summary = summarizer(long_text, max_length=60, min_length=20)\n",
    "\n",
    "print(\"ORIGINAL TEXT:\")\n",
    "print(long_text)\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nSUMMARY:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ASK AI ABOUT THIS**\n",
    ">\n",
    "> Copy this code into Claude or ChatGPT:\n",
    ">\n",
    "> ```python\n",
    "> classifier = pipeline(\"zero-shot-classification\")\n",
    "> result = classifier(\"I need to submit my math homework\", [\"school\", \"sports\", \"food\"])\n",
    "> ```\n",
    ">\n",
    "> Ask: *\"How can this model classify text into categories it was never trained on? What's the trick?\"*\n",
    ">\n",
    "> The answer involves something called \"natural language inference\" — a clever technique that lets the model reason about categories it's never seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **FIND A MODEL: Summarization**\n",
    ">\n",
    "> Summarization models vary widely — some are trained on news articles, some on scientific papers, some on conversations. The model we just used was trained on CNN/Daily Mail news articles.\n",
    ">\n",
    "> 1. Go to [huggingface.co/models?pipeline_tag=summarization&sort=downloads](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads)\n",
    "> 2. Find a model designed for a different domain (try searching \"scientific\" or \"dialogue\")\n",
    "> 3. **Read the model card**: What kind of text is it designed to summarize? What's the recommended max length?\n",
    "> 4. Swap it in below and test it with appropriate text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap in your own summarization model!\n",
    "# Step 1: Go to huggingface.co/models?pipeline_tag=summarization&sort=downloads\n",
    "# Step 2: Find a model, click it, read its card\n",
    "# Step 3: Copy the model ID and paste it below\n",
    "\n",
    "my_summarization_model = \"PASTE YOUR MODEL ID HERE\"\n",
    "# Example: \"facebook/bart-large-cnn\"  (trained on CNN/Daily Mail news)\n",
    "\n",
    "# Uncomment these lines when you have a model ID:\n",
    "# custom_summarizer = pipeline(\"summarization\", model=my_summarization_model)\n",
    "#\n",
    "# # Paste text appropriate for your model's specialty\n",
    "# my_long_text = \"PASTE A LONG TEXT HERE (at least 3-4 sentences)\"\n",
    "#\n",
    "# summary = custom_summarizer(my_long_text, max_length=60, min_length=20)\n",
    "# print(\"SUMMARY:\")\n",
    "# print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Comparison: What Does Each Pipeline Need?\n",
    "\n",
    "| Pipeline | Input | Output | What it needs | Find more models |\n",
    "|----------|-------|--------|---------------|-----------------|\n",
    "| Sentiment | Raw text | Positive/Negative + score | Just text | [text-classification](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads) |\n",
    "| Zero-Shot | Text + categories | Category rankings | Text AND your categories | [zero-shot-classification](https://huggingface.co/models?pipeline_tag=zero-shot-classification&sort=downloads) |\n",
    "| QA | Question + context | Answer + confidence | A question AND a passage | [question-answering](https://huggingface.co/models?pipeline_tag=question-answering&sort=downloads) |\n",
    "| Summarization | Long text | Short text | Enough text to summarize | [summarization](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads) |\n",
    "\n",
    "**Key insight:** You can't give a question to the sentiment model. You can't give raw text to the QA model without a question. The **representation** — how you format the input — must match what the pipeline expects.\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Ask: \"What would happen if you gave the QA model a question but no context? Or gave the sentiment model a whole paragraph?\" Let students reason about why input format matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: The Hugging Face Model Ecosystem (15 minutes)\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Open huggingface.co/models in your browser. Filter by task (e.g., \"Text Classification\"). Show students that THOUSANDS of models exist — not just the defaults we've been using. Click on a sentiment model like `distilbert-base-uncased-finetuned-sst-2-english` and show the model card. Point out: what it was trained on, performance metrics, example usage. Say: \"The default model we used? This is it. Someone trained it, documented it, and shared it — for free.\"\n",
    "\n",
    "### What You Just Used\n",
    "\n",
    "When we wrote `pipeline(\"sentiment-analysis\")`, we used a **default model**. But Hugging Face hosts over 500,000 models. For any task, there are dozens of options — different sizes, languages, and specialties.\n",
    "\n",
    "### Model Cards Revisited\n",
    "\n",
    "Remember model cards from Session 1? Now that you've run models with code, the model card details are more meaningful:\n",
    "\n",
    "- **Training data:** SST-2 (Stanford Sentiment Treebank) — movie reviews labeled positive/negative\n",
    "- **That explains:** Why the model is good at opinion text but might struggle with factual statements\n",
    "- **Model size:** ~67 million parameters — tiny by modern standards (GPT-4 is rumored to have over 1 trillion)\n",
    "\n",
    "The model you just used is a real research artifact. The code you wrote is real professional code. The difference between you and a professional isn't the tools — it's just experience.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## On Your Own: Full Pipeline Exploration (15 minutes)\n",
    "\n",
    "Try all the pipeline types below with your own inputs. For each one, come up with at least 3 of your own test cases.\n",
    "\n",
    "---\n",
    "\n",
    "### Explore: Named Entity Recognition (NER)\n",
    "\n",
    "**What it does:** Identifies and classifies names, places, organizations in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the NER pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Try different texts with people, places, and organizations\n",
    "text = \"Elon Musk founded SpaceX in 2002. The company is headquartered in Hawthorne, California.\"\n",
    "\n",
    "results = ner(text)\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"\\nEntities found:\")\n",
    "for entity in results:\n",
    "    print(f\"  {entity['word']}: {entity['entity_group']} ({entity['score']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore: Text Generation\n",
    "\n",
    "**What it does:** Continues writing from a prompt you give it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text generation pipeline (smaller model that runs on free Colab)\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "# Start of a story\n",
    "prompt = \"Once upon a time, in a world where robots and humans lived together,\"\n",
    "\n",
    "# Generate continuation\n",
    "result = generator(prompt, max_length=80, num_return_sequences=1)\n",
    "\n",
    "print(\"PROMPT:\")\n",
    "print(prompt)\n",
    "print(\"\\nGENERATED CONTINUATION:\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple options from the same prompt\n",
    "prompt = \"The secret to learning AI is\"\n",
    "\n",
    "results = generator(prompt, max_length=50, num_return_sequences=3)\n",
    "\n",
    "print(f\"PROMPT: {prompt}\")\n",
    "print(\"=\" * 50)\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nOption {i}:\")\n",
    "    print(result['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore: Pipeline Chaining\n",
    "\n",
    "Can you use the output of one pipeline as input to another? Try generating text and then analyzing its sentiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text, then analyze its sentiment\n",
    "prompts = [\n",
    "    \"I love it when\",\n",
    "    \"The worst thing about Monday is\",\n",
    "    \"My favorite memory is\"\n",
    "]\n",
    "\n",
    "print(\"GENERATE TEXT --> ANALYZE SENTIMENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for prompt in prompts:\n",
    "    # Generate\n",
    "    generated = generator(prompt, max_length=40, num_return_sequences=1)\n",
    "    full_text = generated[0]['generated_text']\n",
    "\n",
    "    # Analyze sentiment of the generated text\n",
    "    sent_result = sentiment(full_text)\n",
    "\n",
    "    print(f\"\\nGenerated: {full_text}\")\n",
    "    print(f\"Sentiment: {sent_result[0]['label']} ({sent_result[0]['score']:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **ASK AI ABOUT THIS**\n",
    ">\n",
    "> Copy this code into Claude or ChatGPT:\n",
    ">\n",
    "> ```python\n",
    "> qa = pipeline(\"question-answering\")\n",
    "> result = qa(question=\"Who created Python?\", context=\"Python was created by Guido van Rossum in 1991.\")\n",
    "> ```\n",
    ">\n",
    "> Ask: *\"Why does this pipeline need both a question AND a context? Why can't it just answer from what it knows?\"*\n",
    ">\n",
    "> This connects to a key idea: the difference between models that **retrieve** answers from given text vs. models that **generate** answers from memory (like ChatGPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection\n",
    "\n",
    "**1. Which pipeline was most useful or interesting to you?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**2. What's one thing ALL these models had in common in terms of limitations?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**3. Can you think of a real-world application for any of these pipelines?**\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**4. What would you want to build if you could combine these pipelines?**\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Session 2 Checklist\n",
    "\n",
    "- [ ] Ran sentiment analysis on student-suggested sentences\n",
    "- [ ] Tried at least 3 different pipeline types\n",
    "- [ ] Understood why each pipeline needs different input formats\n",
    "- [ ] Explored the Hugging Face model ecosystem\n",
    "- [ ] Found at least one alternative model on the Hub and read its card\n",
    "- [ ] Tried swapping a model ID into a pipeline (or marked the swap-slot cells to try later)\n",
    "- [ ] Completed reflection questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Ahead: Session 3\n",
    "\n",
    "Next session: **AI as Your Coding Partner** — you'll learn how to use ChatGPT and Claude to write code for you, then understand and modify what they create.\n",
    "\n",
    "### Between Sessions\n",
    "\n",
    "Run through this full notebook on your own, trying all 5 pipeline types with your own inputs. Experiment! Try to:\n",
    "- Find sentences that break the sentiment analyzer\n",
    "- Classify unusual categories with zero-shot\n",
    "- Ask tricky questions to the QA pipeline\n",
    "- Summarize different kinds of text\n",
    "- Chain pipelines together in new ways\n",
    "- **Go back to the \"Find a Model\" cells and actually swap in a model you found on the Hub**\n",
    "\n",
    "### Key Code to Remember\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Default model for a task\n",
    "model = pipeline(\"task-name\")\n",
    "\n",
    "# Specific model you found on the Hub\n",
    "model = pipeline(\"task-name\", model=\"author/model-name\")\n",
    "\n",
    "# Use it\n",
    "result = model(\"your input\")\n",
    "```\n",
    "\n",
    "The `model=` argument is your key to using any of the 500,000+ models on Hugging Face!\n",
    "\n",
    "---\n",
    "\n",
    "*Youth Horizons AI Researcher Program — Level 2*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}