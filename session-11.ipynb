{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 11: Independent Project\n",
    "## Build Something That's Yours\n",
    "\n",
    "**Session Length:** 2 hours\n",
    "\n",
    "**Today's Mission:** Share what you built between sessions, get feedback, iterate on your project, and document your work. This is YOUR session -- you drive the code, the instructor helps.\n",
    "\n",
    "### Session Outline\n",
    "| Time | Activity |\n",
    "|------|----------|\n",
    "| 0:00-0:30 | Part 1: Project Workshop (share what you built between sessions) |\n",
    "| 0:30-1:35 | Part 2: Build and Iterate (work time) |\n",
    "| 1:35-2:00 | Part 3: Documentation |\n",
    "\n",
    "### Key Vocabulary\n",
    "| Term | Definition |\n",
    "|------|-----------|\n",
    "| MVP | Minimum Viable Product -- the simplest version that works |\n",
    "| Prototype | A first working version of your tool |\n",
    "| Iteration | Improving something through repeated cycles of testing and changing |\n",
    "| Documentation | Explaining what your code does and why |\n",
    "| Edge Case | Unusual input that might break your tool |\n",
    "| Model Card | A document on the Hub describing a model's training data, intended use, and limitations |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Project Workshop (0:00-0:30)\n",
    "\n",
    "### Share What You Built\n",
    "\n",
    "Each student gets 3-5 minutes to show what they built between sessions. The group discusses: what works, what doesn't, what to try next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** Have each student either share their screen briefly or send you their notebook to run. For each student, ask the group:\n",
    "> - \"What does this tool do well?\"\n",
    "> - \"What would you add to make it more useful?\"\n",
    "> - \"Where might it break?\" (Connect to Sessions 7-8: domain shift, bias, edge cases)\n",
    "\n",
    "### Workshop Notes\n",
    "\n",
    "Use this space to take notes on feedback you receive and ideas from other students' projects.\n",
    "\n",
    "**Feedback on MY project:**\n",
    "- What people liked:\n",
    "- What they suggested:\n",
    "- Edge cases to test:\n",
    "\n",
    "**Ideas from OTHER projects:**\n",
    "-\n",
    "-\n",
    "-\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Build and Iterate (0:30-1:20)\n",
    "\n",
    "This is work time. You have 50 minutes to improve your project based on feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **INSTRUCTOR NOTE:** This session is the exception to the instructor-driven model. Students run their own notebooks. Circulate via Zoom 1:1 to help students who are stuck. Common issues: model loading errors (restart runtime), code from AI that doesn't work (debug together), feature scope too big (help them simplify to MVP).\n",
    "\n",
    "### Model Loading Menu\n",
    "\n",
    "Uncomment the models you need for your project. You do NOT need all of them -- just load what you will actually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.47.1 pillow requests gradio -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: Restart Your Runtime\n",
    "\n",
    "After installing packages, you need to restart the runtime so Python can find them.\n",
    "\n",
    "**Go to: Runtime > Restart runtime**\n",
    "\n",
    "After restarting, come back here and continue running the cells below. You do NOT need to re-run the install cell -- the packages are already installed. Just start from the next code cell.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def load_image(url):\n",
    "    response = requests.get(url)\n",
    "    return Image.open(BytesIO(response.content))\n",
    "\n",
    "print(\"Imports ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **FIND A MODEL: Upgrade Your Project**\n",
    ">\n",
    "> The model menus below list models you have used in this course. But the Hub has **thousands more** -- and your project might benefit from a specialized model you haven't tried yet.\n",
    ">\n",
    "> Browse by task type to find something new:\n",
    ">\n",
    "> - **Sentiment analysis:** [huggingface.co/models?pipeline_tag=text-classification&sort=downloads](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads)\n",
    "> - **Summarization:** [huggingface.co/models?pipeline_tag=summarization&sort=downloads](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads)\n",
    "> - **Text generation:** [huggingface.co/models?pipeline_tag=text-generation&sort=downloads](https://huggingface.co/models?pipeline_tag=text-generation&sort=downloads)\n",
    "> - **Question answering:** [huggingface.co/models?pipeline_tag=question-answering&sort=downloads](https://huggingface.co/models?pipeline_tag=question-answering&sort=downloads)\n",
    "> - **Named entity recognition:** [huggingface.co/models?pipeline_tag=token-classification&sort=downloads](https://huggingface.co/models?pipeline_tag=token-classification&sort=downloads)\n",
    "> - **Image captioning:** [huggingface.co/models?pipeline_tag=image-to-text&sort=downloads](https://huggingface.co/models?pipeline_tag=image-to-text&sort=downloads)\n",
    "> - **Zero-shot image classification:** [huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads](https://huggingface.co/models?pipeline_tag=zero-shot-image-classification&sort=downloads)\n",
    ">\n",
    "> For each model you are considering:\n",
    "> 1. Read the model card -- what was it trained on? What language? What are the limitations?\n",
    "> 2. Check the size -- avoid models with billions of parameters (they need a GPU). Stick to models under ~500M parameters for free Colab CPU.\n",
    "> 3. Copy the model ID (e.g., `cardiffnlp/twitter-roberta-base-sentiment-latest`) and use the swap slot below to try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TEXT MODELS — uncomment what you need\n",
    "# ============================================\n",
    "\n",
    "# Sentiment Analysis (positive/negative)\n",
    "# sentiment = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Twitter-optimized Sentiment\n",
    "# twitter_sentiment = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "# Star Rating Sentiment (1-5 stars)\n",
    "# star_sentiment = pipeline(\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "\n",
    "# Emotion Detection (joy, anger, sadness, fear, surprise, disgust, neutral)\n",
    "# emotions = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", top_k=None)\n",
    "\n",
    "# Zero-Shot Classification (any categories you define)\n",
    "# classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Question Answering (extract answers from a passage)\n",
    "# qa = pipeline(\"question-answering\")\n",
    "\n",
    "# Summarization\n",
    "# summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "# Named Entity Recognition (people, places, organizations)\n",
    "# ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Text Generation\n",
    "# generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "print(\"Uncomment the models you need above, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMAGE MODELS — uncomment what you need\n",
    "# ============================================\n",
    "\n",
    "# Image Captioning\n",
    "# captioner = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Zero-Shot Image Classification (any categories you define)\n",
    "# zero_shot_image = pipeline(\"zero-shot-image-classification\", model=\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "print(\"Uncomment the image models you need above, then re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap Slot: Try a Model From the Hub\n",
    "\n",
    "Found a model on the Hub that might work for your project? Load it here and compare it to the course models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── SWAP SLOT: Load a Hub Model for Your Project ──\n",
    "# Paste the model ID you found on the Hub and set the task:\n",
    "\n",
    "my_model = \"PASTE YOUR MODEL ID HERE\"\n",
    "my_task = \"sentiment-analysis\"  # Change to your task: \"summarization\", \"text-generation\", \"ner\", etc.\n",
    "\n",
    "# Uncomment the next two lines to load your model:\n",
    "# my_pipeline = pipeline(my_task, model=my_model)\n",
    "# print(f\"Loaded: {my_model} for {my_task}\")\n",
    "\n",
    "print(\"Swap slot ready. Uncomment above to load your model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Test your Hub model ──\n",
    "# Uncomment and modify for your task:\n",
    "\n",
    "# result = my_pipeline(\"Test this input with your model\")\n",
    "# print(result)\n",
    "\n",
    "print(\"Uncomment the code above after loading your model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Project Workspace\n",
    "\n",
    "Use the cells below to build and test your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# YOUR MAIN PROJECT FUNCTION\n",
    "# ============================================\n",
    "\n",
    "def my_project(input_data):\n",
    "    \"\"\"\n",
    "    REPLACE: Describe what your function does.\n",
    "\n",
    "    Args:\n",
    "        input_data: REPLACE with description of input\n",
    "\n",
    "    Returns:\n",
    "        REPLACE with description of output\n",
    "    \"\"\"\n",
    "    print(\"MY PROJECT\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# TEST YOUR FUNCTION\n",
    "# ============================================\n",
    "\n",
    "test_input = \"REPLACE WITH YOUR TEST INPUT\"\n",
    "\n",
    "# result = my_project(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPROVED VERSION (after testing)\n",
    "# ============================================\n",
    "\n",
    "# Copy your function here and make improvements based on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# MORE TESTING\n",
    "# ============================================\n",
    "\n",
    "# Try different inputs, especially edge cases\n",
    "# What happens with empty input?\n",
    "# What happens with very long input?\n",
    "# What happens with input in a different domain? (Session 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DEMO EXAMPLES\n",
    "# These are the examples you will show in your presentation\n",
    "# ============================================\n",
    "\n",
    "print(\"DEMO 1: [Description]\")\n",
    "print(\"-\" * 40)\n",
    "# demo_input_1 = \"...\"\n",
    "# my_project(demo_input_1)\n",
    "\n",
    "print(\"\\nDEMO 2: [Description]\")\n",
    "print(\"-\" * 40)\n",
    "# demo_input_2 = \"...\"\n",
    "# my_project(demo_input_2)\n",
    "\n",
    "print(\"\\nDEMO 3: [Description]\")\n",
    "print(\"-\" * 40)\n",
    "# demo_input_3 = \"...\"\n",
    "# my_project(demo_input_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Project UI: Gradio (Book Enhancement)\n",
    "\n",
    "If your `my_project()` function works, you can wrap it in a simple UI so people can test it without reading code.\n",
    "\n",
    "This is a strong upgrade for Session 12 demos because you get a shareable interface.\n",
    "\n",
    "> **INSTRUCTOR NOTE:** Have students finish a working `my_project()` first. Then use this section to package it for presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Wrapper for text-input projects\n",
    "# If your project needs image/audio input, change the input component type.\n",
    "def my_project_text_wrapper(user_input):\n",
    "    try:\n",
    "        result = my_project(user_input)\n",
    "        if result is None:\n",
    "            return \"Your my_project() function returned None. Update it to return a value.\"\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "project_demo = gr.Interface(\n",
    "    fn=my_project_text_wrapper,\n",
    "    title=\"Student AI Project Demo\",\n",
    "    description=\"Type input and test the project output.\",\n",
    "    inputs=gr.Textbox(label=\"Input\", lines=3, placeholder=\"Enter test input\"),\n",
    "    outputs=gr.Textbox(label=\"Output\"),\n",
    "    allow_flagging=\"never\",\n",
    ")\n",
    "\n",
    "print(\"Gradio interface ready. Launch in the next cell when your project works.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch UI (uncomment when ready)\n",
    "# project_demo.launch(share=True)\n",
    "\n",
    "print(\"When ready, uncomment launch() to create a shareable demo link.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Documentation (1:35-2:00)\n",
    "\n",
    "Good documentation separates a school exercise from a real project. Answer these questions honestly -- knowing your project's limits shows MORE understanding than pretending it is perfect.\n",
    "\n",
    "### Thinking Like a Researcher\n",
    "\n",
    "**1. What does your tool do?** (1-2 sentences)\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**2. How would you know if your tool works well?**\n",
    "\n",
    "What does \"success\" look like? Be specific. (Example: \"The sentiment classifier should match my own judgment at least 80% of the time.\")\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**3. What does your tool NOT handle well?**\n",
    "\n",
    "Every AI tool has limits. What kinds of inputs might confuse it? What situations is it NOT designed for? Being honest about limitations is a sign of understanding, not weakness. (Connect to Sessions 7-8.)\n",
    "\n",
    "Your answer:\n",
    "\n",
    "**4. If someone asked \"why did you build it this way?\", what would you say?**\n",
    "\n",
    "What trade-offs did you make? What did you prioritize?\n",
    "\n",
    "Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **READ THE MODEL CARD: Document Your Models**\n",
    ">\n",
    "> Good project documentation includes understanding the models you used. For each model in your project, visit its page on the Hub and answer:\n",
    ">\n",
    "> 1. **What was it trained on?** (What dataset? How much data?)\n",
    "> 2. **What language(s) does it support?** (English only? Multilingual?)\n",
    "> 3. **What are its known limitations?** (The model card usually has a \"Limitations\" or \"Bias\" section)\n",
    "> 4. **Who made it?** (A company? A research lab? An individual?)\n",
    ">\n",
    "> Example: If you used `cardiffnlp/twitter-roberta-base-sentiment-latest`, go to [huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) and look for these details.\n",
    ">\n",
    "> Include this information in your README below. Knowing your model's background makes your project documentation **professional-grade** -- it shows you understand what powers your tool, not just how to call it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project README Template\n",
    "\n",
    "Fill this in. You will use it in your final presentation.\n",
    "\n",
    "```\n",
    "Project: [Name]\n",
    "\n",
    "What it does: [1-2 sentences]\n",
    "\n",
    "Who it's for: [Who would use this tool?]\n",
    "\n",
    "Models used:\n",
    "- [Model 1]: [what it does in your project]\n",
    "  - Trained on: [dataset from model card]\n",
    "  - Limitations: [from model card]\n",
    "- [Model 2]: [what it does in your project]\n",
    "  - Trained on: [dataset from model card]\n",
    "  - Limitations: [from model card]\n",
    "\n",
    "Example:\n",
    "  Input: [example input]\n",
    "  Output: [example output]\n",
    "\n",
    "Limitations:\n",
    "- [What it doesn't handle well]\n",
    "- [What domain shift issues might affect it]\n",
    "\n",
    "What I learned building this:\n",
    "- [Key learning 1]\n",
    "- [Key learning 2]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Your Own\n",
    "\n",
    "### Before Session 12\n",
    "\n",
    "- [ ] **Continue building** -- get your project to a state you are proud of\n",
    "- [ ] **Prepare 3 demo examples** (easy case, interesting case, edge case)\n",
    "- [ ] **Write your documentation** using the template above\n",
    "- [ ] **Read the model cards** for every model in your project\n",
    "- [ ] **Practice explaining** your project in under 2 minutes\n",
    "- [ ] **Upload to GitHub** -- save your notebook to your `ai-explorer` repository\n",
    "\n",
    "### Presentation Format (Session 12)\n",
    "\n",
    "Each student gets ~8 minutes:\n",
    "- **5 minutes:** Demo your project with 3 examples\n",
    "- **3 minutes:** Questions from the group\n",
    "\n",
    "You do NOT need slides. You just need a working notebook and 3 good examples.\n",
    "\n",
    "---\n",
    "\n",
    "### Checklist: Before You Leave\n",
    "\n",
    "- [ ] Shared your project with the group and received feedback\n",
    "- [ ] Made at least one improvement based on feedback\n",
    "- [ ] Tested your project with at least 3 different inputs\n",
    "- [ ] Answered the \"Thinking Like a Researcher\" questions\n",
    "- [ ] Read the model card for at least one model you used\n",
    "- [ ] Started your project README (with model card details)\n",
    "- [ ] Have a plan for what to finish before Session 12\n",
    "- [ ] Saved your work (File > Save a copy in Drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Looking Ahead\n",
    "\n",
    "Next session is the final session. You will present your project, reflect on what you have learned across all 12 sessions, and get a preview of what Level 3 looks like. Come ready to show what you built.\n",
    "\n",
    "See you next session.\n",
    "\n",
    "---\n",
    "\n",
    "*Youth Horizons AI Researcher Program - Level 2*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}